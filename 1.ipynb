{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function1 ---> connect to buckect and retrieve the objects from the bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s3://rand1/hello.parquet']\n",
      "   hello\n",
      "0  world\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "bucket = 'rand1'\n",
    "s3_client = boto3.client(\"s3\")\n",
    "with open(\"./load_test_db/hello_test.parquet\", \"rb\") as f:\n",
    "    s3_client.upload_fileobj(f, f\"{bucket}\", \"hello.parquet\")\n",
    "bucket_objects = s3_client.list_objects_v2(Bucket = bucket)\n",
    "assert bucket_objects['KeyCount'] == 1\n",
    "file_paths = [f's3://{bucket}/{obj[\"Key\"]}' for obj in bucket_objects['Contents']]\n",
    "print(file_paths)\n",
    "for file_path in file_paths:\n",
    "    s3_file = pq.ParquetDataset(file_path)\n",
    "    table = s3_file.read().to_pandas()\n",
    "    df= pd.DataFrame(table)\n",
    "    print(df)\n",
    "assert df.columns.tolist() == ['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "def retrive_files(bucket):\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    bucket = s3_client.list_objects_v2(Bucket = bucket)\n",
    "    return bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 1.25s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "from moto import mock_s3\n",
    "import pytest\n",
    "import pyarrow.parquet as pq\n",
    "import pg8000\n",
    "from pyarrow import fs\n",
    "\n",
    "@pytest.fixture(scope='function')\n",
    "def aws_credentials():\n",
    "    \"\"\"Mocked AWS Credentials for moto.\"\"\"\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = 'test'\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = 'test'\n",
    "    os.environ['AWS_SECURITY_TOKEN'] = 'test'\n",
    "    os.environ['AWS_SESSION_TOKEN'] = 'test'\n",
    "    os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "@mock_s3\n",
    "def test_creating_mock_s3():\n",
    "    conn = boto3.client(\"s3\", region_name=\"us-east-1\")\n",
    "    res = conn.create_bucket(Bucket=\"test_bucket_29\")\n",
    "    assert res['ResponseMetadata']['HTTPStatusCode'] == 200\n",
    "\n",
    "@mock_s3\n",
    "def test_accessing_the_objects_in_the_bucket():\n",
    "    conn = boto3.client(\"s3\", region_name=\"us-east-1\")\n",
    "    res = conn.create_bucket(Bucket=\"test_bucket_29\")\n",
    "    parquet_files = retrive_files('test_bucket_29')\n",
    "    assert parquet_files['KeyCount'] == 0\n",
    "\n",
    "@mock_s3\n",
    "def test_retreiving_objects_in_the_bucket():\n",
    "    bucket = \"test_bucket_29\"\n",
    "    conn = boto3.client(\"s3\")\n",
    "    res = conn.create_bucket(Bucket=bucket)\n",
    "    parquet_files = retrive_files(bucket)\n",
    "    # uploading some fake data to bucket\n",
    "    with open(\"./load_test_db/hello_test.parquet\", \"rb\") as f:\n",
    "        conn.upload_fileobj(f, f\"{bucket}\", \"hello.parquet\")\n",
    "    parquet_files = retrive_files(bucket)\n",
    "    assert parquet_files['KeyCount'] == 1\n",
    "    \n",
    "@pytest.fixture\n",
    "def test_retreiving_objects_in_the_bucketss():\n",
    "    bucket =\"rand2\"\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    res = s3_client.create_bucket(Bucket=bucket,CreateBucketConfiguration={'LocationConstraint': 'eu-west-2'})\n",
    "    with open(\"./load_test_db/hello_test.parquet\", \"rb\") as f:\n",
    "        s3_client.upload_fileobj(f, f\"{bucket}\", \"hello.parquet\")\n",
    "    bucket_objects = retrive_files(bucket)\n",
    "    file_paths = [f's3://{bucket}/{obj[\"Key\"]}' for obj in bucket_objects['Contents']]\n",
    "    for file_path in file_paths:\n",
    "        s3_file = pq.ParquetDataset(file_path)\n",
    "        table = s3_file.read().to_pandas()\n",
    "        df= pd.DataFrame(table)\n",
    "    assert df.columns.tolist() == ['hello']\n",
    "\n",
    "# @pytest.fixture\n",
    "# def test_warehouse_connection():\n",
    "#     connect = make_warehouse_connection()\n",
    "#     assert isinstance(connect, pg8000.Connection)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pg8000.legacy.Connection object at 0x7fbc667cebe0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from os.path import join, dirname\n",
    "from pathlib import Path\n",
    "import pg8000\n",
    "def make_warehouse_connection():\n",
    "    # dotenv_path = join(dirname(__file__), '../config/.env.data_warehouse')\n",
    "    dotenv_path = Path('./config/.env.data_warehouse')\n",
    "    load_dotenv(dotenv_path)\n",
    "    API_HOST =  os.environ[\"host\"]\n",
    "    API_USER = os.environ[\"user\"]\n",
    "    API_PASS = os.environ[\"password\"]\n",
    "    API_DBASE = os.environ[\"database\"]\n",
    "    conn = pg8000.connect(\n",
    "        host=API_HOST,\n",
    "        user=API_USER,\n",
    "        password=API_PASS,\n",
    "        database=API_DBASE\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "print(make_warehouse_connection())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
